{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30c99c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from misc import companies, currencies\n",
    "import re\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from langchain.schema import HumanMessage\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2801ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71beb90bd4d949bda91f37aee8e51a46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "987a1bce10454ae58c7fffd50b0a15ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "424ce41f17074b5bbcf8390c5172c8a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0b55b0c49d143389946a3de8119a88f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cefbd53b8df04f168f7fc7906f000b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66aaec7427e3402b9f9d2ed2378aa38b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c3a2cd2cf4e43798166ce7e17e974a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7e0f26723084ac8852c36e717a8dbf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67cc1a20e1246fcbe09c4ff758ef2fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac896d6d41e24ab79bdebc0da8c7e781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63c7fd04b60b419bb07fb427798b2809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "def convert_to_float(text):\n",
    "    # Remove non-numeric characters and convert to float\n",
    "    # Extract numbers and handle special characters\n",
    "    text = text.replace('~', '').strip()  # Remove approximate symbol\n",
    "    numbers = re.findall(r'[\\d.]+', text)\n",
    "    if not numbers:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        number = float(numbers[0])\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    # Handle multipliers\n",
    "\n",
    "    if 'billion' in text.lower():\n",
    "        number *= 1000000000\n",
    "    elif 'million' in text.lower():\n",
    "        number *= 1000000\n",
    "    elif 'thousand' in text.lower():\n",
    "        number *= 1000\n",
    "\n",
    "    return number\n",
    "\n",
    "def extract_steps(text):\n",
    "    # Find all instances of \"Step\" at the beginning of a line or after newline\n",
    "    steps = re.finditer(r'(?:^|\\n)\\s*Step\\s+(\\d+)', text)\n",
    "    step_starts = [step.span()[0] for step in steps]\n",
    "    step_spans = [(step_starts[idx], step_starts[idx+1]) for idx in range(len(step_starts) - 1)]\n",
    "    # Add the last step span\n",
    "    step_spans.append((step_starts[-1], len(text)))\n",
    "    step_strings = [text[start:end].strip() for start, end in step_spans]\n",
    "    # Remove leading \"Step X\" from each step\n",
    "    step_strings = [re.sub(r'(?i)Step\\s+\\d+\\s*:', '', step).strip() for step in step_strings]\n",
    "    # Find final answer\n",
    "    # Find the last step\n",
    "    last_step = step_strings[-1]\n",
    "    # Find the last '=' and extract everything after it until the end\n",
    "    final_answer_match = re.search(r'=\\s*([^=]+)$', last_step)\n",
    "    final_answer = final_answer_match.group(1).strip() if final_answer_match else ''\n",
    "    final_answer = final_answer.split('\\n')[0]\n",
    "    final_answer = convert_to_float(final_answer)\n",
    "    # Remove extra spaces\n",
    "    step_strings = [re.sub(r'\\s+', ' ', step) for step in step_strings]\n",
    "    return step_strings, final_answer\n",
    "\n",
    "\n",
    "def eval(gt, pred):\n",
    "    \n",
    "    gt_steps, gt_final_answer = extract_steps(gt)\n",
    "    pred_steps, pred_final_answer = extract_steps(pred)\n",
    "\n",
    "    gt_steps_embeddings = model.encode(gt_steps)\n",
    "    pred_steps_embeddings = model.encode(pred_steps)\n",
    "\n",
    "    similarity_matrix = cosine_similarity(gt_steps_embeddings, pred_steps_embeddings)\n",
    "    max_similarities_backward = np.max(similarity_matrix, axis=1)\n",
    "    max_similarities_forward = np.max(similarity_matrix, axis=0)\n",
    "    binarized_similarity_backward = max_similarities_backward > 0.7\n",
    "    binarized_similarity_forward = max_similarities_forward > 0.7\n",
    "    recall = float(np.sum(binarized_similarity_backward) / len(gt_steps))\n",
    "    precision = float(np.sum(binarized_similarity_forward) / len(pred_steps))\n",
    "\n",
    "    # Check final answer match\n",
    "    if gt_final_answer is None or pred_final_answer is None:\n",
    "        final_answer_match = 0\n",
    "    else:\n",
    "        final_answer_match = int(abs(gt_final_answer - pred_final_answer)/gt_final_answer < 0.05)\n",
    "\n",
    "    return recall, precision, final_answer_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e160f158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seed': 2763771162, 'id': '5', 'level': 'Advanced', 'question': 'A systemic risk event causes equities to lose 29.5% and bonds to lose 15.5%. If a portfolio is 73% equities and 27% bonds worth $1,274,342, what is the portfolio value after the event?', 'solution': 'Step 1: Calculate equity value:\\n  73% of 1,274,342 = 930,269.66.\\nStep 2: Calculate bond value:\\n  27% of 1,274,342 = 344,072.34.\\nStep 3: Calculate losses:\\n  Equities lose 930,269.66 * 0.29 = 274,429.55, Bonds lose 344,072.34 * 0.15 = 53,331.21.\\nStep 4: Subtract losses:\\n  The portfolio value = 1,274,342 - 274,429.55 - 53,331.21 = 946,581.24.', 'topic': 'risk_management', 'subtopic': 'scenario_plan', 'generation': \"Here's a step-by-step solution to calculate the portfolio value after the systemic risk event:\\n\\n**Step 1: Calculate the initial value of the equity portion of the portfolio.**\\n\\n*   Portfolio value = $1,274,342\\n*   Equity allocation = 73%\\n*   Initial equity value = $1,274,342 * 0.73 = $930,269.66\\n\\n**Step 2: Calculate the initial value of the bond portion of the portfolio.**\\n\\n*   Portfolio value = $1,274,342\\n*   Bond allocation = 27%\\n*   Initial bond value = $1,274,342 * 0.27 = $344,072.34\\n\\n**Step 3: Calculate the loss in value of the equity portion.**\\n\\n*   Equity loss percentage = 29.5%\\n*   Initial equity value = $930,269.66\\n*   Equity loss amount = $930,269.66 * 0.295 = $274,329.55\\n\\n**Step 4: Calculate the loss in value of the bond portion.**\\n\\n*   Bond loss percentage = 15.5%\\n*   Initial bond value = $344,072.34\\n*   Bond loss amount = $344,072.34 * 0.155 = $53,331.21\\n\\n**Step 5: Calculate the remaining value of the equity portion.**\\n\\n*   Initial equity value = $930,269.66\\n*   Equity loss amount = $274,329.55\\n*   Remaining equity value = $930,269.66 - $274,329.55 = $655,940.11\\n\\n**Step 6: Calculate the remaining value of the bond portion.**\\n\\n*   Initial bond value = $344,072.34\\n*   Bond loss amount = $53,331.21\\n*   Remaining bond value = $344,072.34 - $53,331.21 = $290,741.13\\n\\n**Step 7: Calculate the total portfolio value after the event.**\\n\\n*   Remaining equity value = $655,940.11\\n*   Remaining bond value = $290,741.13\\n*   Total portfolio value = $655,940.11 + $290,741.13 = $946,681.24\\n\\n**Answer:** The portfolio value after the event is $946,681.24.\", 'model': 'gemma_3_27b_instruct', 'recall': 0.0, 'precision': 0.0, 'final_answer_match': 0}\n",
      "Step 1: Calculate equity value:\n",
      "  73% of 1,274,342 = 930,269.66.\n",
      "Step 2: Calculate bond value:\n",
      "  27% of 1,274,342 = 344,072.34.\n",
      "Step 3: Calculate losses:\n",
      "  Equities lose 930,269.66 * 0.29 = 274,429.55, Bonds lose 344,072.34 * 0.15 = 53,331.21.\n",
      "Step 4: Subtract losses:\n",
      "  The portfolio value = 1,274,342 - 274,429.55 - 53,331.21 = 946,581.24.\n",
      "946681.24\n",
      "930269.66\n"
     ]
    }
   ],
   "source": [
    "# def convert_to_float(text):\n",
    "#     # Remove non-numeric characters and convert to float\n",
    "#     # Extract numbers and handle special characters\n",
    "#     text = text.replace('~', '').strip()  # Remove approximate symbol\n",
    "#     text = text.replace('$', '').replace(',', '')  # Remove dollar sign and commas\n",
    "#     numbers = re.findall(r'[\\d.]+', text)\n",
    "#     if not numbers:\n",
    "#         return None\n",
    "    \n",
    "#     try:\n",
    "#         number = float(numbers[0])\n",
    "#     except:\n",
    "#         return None\n",
    "\n",
    "#     # Handle multipliers\n",
    "\n",
    "#     if 'billion' in text.lower():\n",
    "#         number *= 1000000000\n",
    "#     elif 'million' in text.lower():\n",
    "#         number *= 1000000\n",
    "#     elif 'thousand' in text.lower():\n",
    "#         number *= 1000\n",
    "\n",
    "#     return number\n",
    "\n",
    "# def extract_final_answer(step):\n",
    "#     final_answer_match = re.search(r'=\\s*([^=]+)$', step)\n",
    "#     final_answer = final_answer_match.group(1).strip() if final_answer_match else ''\n",
    "#     final_answer = final_answer.split('\\n')[0]\n",
    "#     final_answer = convert_to_float(final_answer)\n",
    "#     return final_answer\n",
    "\n",
    "\n",
    "def convert_to_float(text):\n",
    "    # Remove non-numeric characters and convert to float\n",
    "    # Extract numbers and handle special characters\n",
    "    text = text.replace('~', '').strip()  # Remove approximate symbol\n",
    "    text = text.replace('$', '').replace(',', '')  # Remove dollar sign and commas\n",
    "    numbers = re.findall(r'[\\d.]+', text)\n",
    "    if not numbers:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        number = float(numbers[0])\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    # Handle multipliers\n",
    "\n",
    "    if 'billion' in text.lower():\n",
    "        number *= 1000000000\n",
    "    elif 'million' in text.lower():\n",
    "        number *= 1000000\n",
    "    elif 'thousand' in text.lower():\n",
    "        number *= 1000\n",
    "\n",
    "    return number\n",
    "\n",
    "def extract_final_answer(step):\n",
    "    # Try capturing explicit \"Answer: $\" pattern\n",
    "    answer_match = re.search(r'\\*\\*Answer:\\*\\*\\s*.*?\\$?([\\d,]+\\.\\d{2})', step)\n",
    "    if answer_match:\n",
    "        return convert_to_float(answer_match.group(1))\n",
    "\n",
    "    # Fallback: last valid dollar-format number after =\n",
    "    final_answer_match = re.search(r'=\\s*\\$?([\\d,]+\\.\\d{2})', step)\n",
    "    if final_answer_match:\n",
    "        return convert_to_float(final_answer_match.group(1))\n",
    "\n",
    "    return None\n",
    "\n",
    "for line in open('../human_eval/gemma_3_27b_instruct.jsonl').readlines():\n",
    "    data = json.loads(line)\n",
    "    print(data)\n",
    "    generation = data['generation']\n",
    "    solution = data['solution']\n",
    "    gt_final_answer = extract_final_answer(generation)\n",
    "    pred_final_answer = extract_final_answer(solution)\n",
    "    print(solution)\n",
    "    print(gt_final_answer)\n",
    "    print(pred_final_answer)\n",
    "    # print(pred_final_answer)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dafe1690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def add_dollar_signs(text):\n",
    "    # Match candidate numbers\n",
    "    pattern = re.compile(r'\\b\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?|\\b\\d+(?:\\.\\d+)?')\n",
    "\n",
    "    def is_money(match):\n",
    "        span = match.span()\n",
    "        start, end = span\n",
    "        number = match.group()\n",
    "\n",
    "        # Check what comes before and after the number\n",
    "        before = text[max(0, start-8):start]\n",
    "        after = text[end:end+2]\n",
    "\n",
    "        # Exclude if already has a dollar sign\n",
    "        if before.endswith('$'):\n",
    "            return False\n",
    "        # Exclude step numbers\n",
    "        if \"Step \" in before:\n",
    "            return False\n",
    "        # Exclude percentages\n",
    "        if after.startswith('%'):\n",
    "            return False\n",
    "        # Exclude multipliers\n",
    "        if before.strip().endswith('*') or before.strip().endswith('/'):\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    # Replace only valid monetary numbers\n",
    "    result = []\n",
    "    last_idx = 0\n",
    "    for match in pattern.finditer(text):\n",
    "        if is_money(match):\n",
    "            result.append(text[last_idx:match.start()] + '$' + match.group())\n",
    "        else:\n",
    "            result.append(text[last_idx:match.end()])\n",
    "        last_idx = match.end()\n",
    "    result.append(text[last_idx:])\n",
    "    return ''.join(result)\n",
    "\n",
    "def process_entry(entry):\n",
    "    if \"solution\" in entry and isinstance(entry[\"solution\"], str):\n",
    "        entry[\"solution\"] = add_dollar_signs(entry[\"solution\"])\n",
    "    return entry\n",
    "\n",
    "input_file = \"../human_eval/gemma_3_27b_instruct.jsonl\"\n",
    "output_file = \"../human_eval/gemma_3_27b_instruct_new.jsonl\"\n",
    "\n",
    "with open(input_file, 'r', encoding='utf-8') as fin, open(output_file, 'w', encoding='utf-8') as fout:\n",
    "    for line in fin:\n",
    "        data = json.loads(line)\n",
    "        updated = process_entry(data)\n",
    "        fout.write(json.dumps(updated, ensure_ascii=False) + '\\n')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "564a1103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "946681.24\n"
     ]
    }
   ],
   "source": [
    "def convert_to_float(text):\n",
    "    # Remove non-numeric characters and convert to float\n",
    "    # Extract numbers and handle special characters\n",
    "    text = text.replace('~', '').strip()  # Remove approximate symbol\n",
    "    text = text.replace('$', '').replace(',', '')  # Remove dollar sign and commas\n",
    "    numbers = re.findall(r'[\\d.]+', text)\n",
    "    if not numbers:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        number = float(numbers[0])\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    # Handle multipliers\n",
    "\n",
    "    if 'billion' in text.lower():\n",
    "        number *= 1000000000\n",
    "    elif 'million' in text.lower():\n",
    "        number *= 1000000\n",
    "    elif 'thousand' in text.lower():\n",
    "        number *= 1000\n",
    "\n",
    "    return number\n",
    "\n",
    "print(convert_to_float('$946,681.24'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5703657",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "encode() argument 'encoding' must be str, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f_pred:\n\u001b[1;32m     11\u001b[0m     json_line \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(line)\n\u001b[0;32m---> 12\u001b[0m     recall, precision, final_answer_match \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mjson_line\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msolution\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_line\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgeneration\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     json_line[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m recall\n\u001b[1;32m     14\u001b[0m     json_line[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m precision\n",
      "Cell \u001b[0;32mIn[2], line 57\u001b[0m, in \u001b[0;36meval\u001b[0;34m(gt, pred)\u001b[0m\n\u001b[1;32m     54\u001b[0m gt_steps, gt_final_answer \u001b[38;5;241m=\u001b[39m extract_steps(gt)\n\u001b[1;32m     55\u001b[0m pred_steps, pred_final_answer \u001b[38;5;241m=\u001b[39m extract_steps(pred)\n\u001b[0;32m---> 57\u001b[0m gt_steps_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgt_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m pred_steps_embeddings \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(pred_steps)\n\u001b[1;32m     60\u001b[0m similarity_matrix \u001b[38;5;241m=\u001b[39m cosine_similarity(gt_steps_embeddings, pred_steps_embeddings)\n",
      "\u001b[0;31mTypeError\u001b[0m: encode() argument 'encoding' must be str, not list"
     ]
    }
   ],
   "source": [
    "model_results = {\n",
    "    model: load_jsonl(f'../results/ci/{model}') \n",
    "            for model in os.listdir(f'../results/ci/') if model.endswith('.jsonl')\n",
    "    }\n",
    "\n",
    "for model in os.listdir('../results/ci'):\n",
    "    if model.endswith('.jsonl'):\n",
    "        with open(f'../results/ci/{model.split(\".\")[0]}_evals.jsonl', 'w') as f_eval:\n",
    "            with open(f'../results/ci/{model}', 'r') as f_pred:\n",
    "                for line in f_pred:\n",
    "                    json_line = json.loads(line)\n",
    "                    recall, precision, final_answer_match = eval(json_line['solution'], json_line['generation'])\n",
    "                    json_line['recall'] = recall\n",
    "                    json_line['precision'] = precision\n",
    "                    json_line['final_answer_match'] = final_answer_match\n",
    "                    f_eval.write(json.dumps(json_line) + '\\n')\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
